{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c8497f-1534-4929-aff1-ef9970a576a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 18:28:31.974008: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "# Ignore specific warning from pretty_midi\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, module='pretty_midi.pretty_midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ab63415-6f0d-4e5e-b15c-b393d8df3546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore specific warning from pretty_midi\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, module='pretty_midi.pretty_midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad136912-48e2-4a98-82b9-c7e4869b87f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to convert MIDI to piano roll\n",
    "def midi_to_piano_roll(midi_file):\n",
    "    try:\n",
    "        midi = pretty_midi.PrettyMIDI(midi_file)\n",
    "        piano_roll = midi.get_piano_roll(fs=25)\n",
    "        return np.asarray(piano_roll)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {midi_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the data\n",
    "def load_data_from_folder(folder):\n",
    "    composers = os.listdir(folder)\n",
    "    labels, piano_rolls = [], []\n",
    "    for composer in composers:\n",
    "        composer_path = os.path.join(folder, composer)\n",
    "        if os.path.isdir(composer_path):\n",
    "            for midi_file in os.listdir(composer_path):\n",
    "                if midi_file.endswith('.midi') or midi_file.endswith('.mid'):\n",
    "                    piano_roll = midi_to_piano_roll(os.path.join(composer_path, midi_file))\n",
    "                    if piano_roll is not None:\n",
    "                        labels.append(composer)\n",
    "                        piano_rolls.append(piano_roll)\n",
    "    return piano_rolls, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00587e97-2c80-431d-be3c-ba2b81e891b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, train_labels = load_data_from_folder('/Users/fediajahangiry/Downloads/FP_AAI_511_NNL_SUM2_Team3/Composer_Dataset2/NN_midi_files_extended/train')\n",
    "dev_data, dev_labels = load_data_from_folder('/Users/fediajahangiry/Downloads/FP_AAI_511_NNL_SUM2_Team3/Composer_Dataset2/NN_midi_files_extended/test')\n",
    "test_data, test_labels = load_data_from_folder('/Users/fediajahangiry/Downloads/FP_AAI_511_NNL_SUM2_Team3/Composer_Dataset2/NN_midi_files_extended/dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f13d5d6-1333-4dd7-850e-77477e7c632a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_labels)\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "y_dev = label_encoder.transform(dev_labels)\n",
    "y_dev = to_categorical(y_dev)\n",
    "\n",
    "y_test = label_encoder.transform(test_labels)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8d2afaa-6499-4d02-b4ee-2cd68150a820",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 14016)\n"
     ]
    }
   ],
   "source": [
    "sample_shape = train_data[0].shape\n",
    "print(sample_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b893156-eb93-439f-beff-eaabdced426c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 10580)\n"
     ]
    }
   ],
   "source": [
    "sample_shape = dev_data[0].shape\n",
    "print(sample_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d94f9c9f-217e-446b-8fd9-4b65486fbe08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 8764)\n"
     ]
    }
   ],
   "source": [
    "sample_shape = test_data[0].shape\n",
    "print(sample_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2e0aec-dd53-42a1-a8fb-101745cec119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fixed_length = 10627  # Chosen based on the 75th percentile\n",
    "\n",
    "# Function to limit sequences to a fixed length\n",
    "def limit_sequence_length(data, fixed_length):\n",
    "    limited_data = []\n",
    "    for sample in data:\n",
    "        if sample.shape[1] > fixed_length:\n",
    "            limited_sample = sample[:, :fixed_length]\n",
    "        else:\n",
    "            limited_sample = np.pad(sample, ((0, 0), (0, fixed_length - sample.shape[1])), mode='constant', constant_values=0)\n",
    "        limited_data.append(limited_sample)\n",
    "    return np.array(limited_data)\n",
    "\n",
    "# Adjust all datasets\n",
    "X_train = limit_sequence_length(train_data, fixed_length).reshape(-1, 128, fixed_length, 1)\n",
    "X_dev = limit_sequence_length(dev_data, fixed_length).reshape(-1, 128, fixed_length, 1)\n",
    "X_test = limit_sequence_length(test_data, fixed_length).reshape(-1, 128, fixed_length, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ead0615-bb2e-4e0d-af7c-93d385227660",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 7/12 [================>.............] - ETA: 18:45 - loss: 1534.1906 - accuracy: 0.1786"
     ]
    }
   ],
   "source": [
    "number_of_classes = y_train.shape[1]\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128, 10627, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_dev, y_dev), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdca2cd-90aa-47fb-b73d-4006ea65a342",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First Convolutional Layer\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second Convolutional Layer\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten and Fully Connected Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(y_train_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "# Use RMSprop optimizer as an alternative\n",
    "optimizer = RMSprop(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_categorical, validation_data=(X_dev, y_dev_categorical), epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8a1ee-01b5-4217-b6db-a38c2bb39332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f56273-60f5-4e52-883a-3a2ff4dc0a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load CSV data\n",
    "train_df = pd.read_csv('/Users/fediajahangiry/Downloads/FP_AAI_511_NNL_SUM2_Team3/csv_file/midi_train_processed.csv')\n",
    "dev_df = pd.read_csv('/Users/fediajahangiry/Downloads/FP_AAI_511_NNL_SUM2_Team3/csv_file/midi_test_processed.csv')\n",
    "test_df = pd.read_csv('/Users/fediajahangiry/Downloads/FP_AAI_511_NNL_SUM2_Team3/csv_file/midi_val_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52597a-11aa-4575-9187-c69440cd53a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timesteps = 128\n",
    "features_per_timestep = X_train.shape[1] // timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac688e-4264-450b-8129-87843da8c495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_sequences = X_train.shape[1] // timesteps\n",
    "print(num_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8608fefb-6b76-4ee5-99a6-10fadcc3c562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_per_timestep = X_train.shape[1] // num_sequences\n",
    "print(features_per_timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f2881-d97d-43d6-aa52-4cd5046010df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract features and labels\n",
    "X_train = train_df.iloc[:, :-1].values\n",
    "y_train = train_df.iloc[:, -1].values\n",
    "X_dev = dev_df.iloc[:, :-1].values\n",
    "y_dev = dev_df.iloc[:, -1].values\n",
    "X_test = test_df.iloc[:, :-1].values\n",
    "y_test = test_df.iloc[:, -1].values\n",
    "\n",
    "# Define fixed values based on the provided info\n",
    "timesteps = 128\n",
    "num_sequences = 117\n",
    "features_per_timestep = 128\n",
    "\n",
    "# Pad or truncate sequences to a fixed length\n",
    "def pad_or_truncate(data, fixed_length):\n",
    "    padded_data = []\n",
    "    for sample in data:\n",
    "        if len(sample) < fixed_length:\n",
    "            padded_data.append(np.pad(sample, (0, fixed_length - len(sample)), 'constant'))\n",
    "        else:\n",
    "            padded_data.append(sample[:fixed_length])\n",
    "    return np.array(padded_data)\n",
    "\n",
    "# Adjust the X_train, X_dev and X_test to match the expected length\n",
    "expected_length = timesteps * features_per_timestep\n",
    "X_train = pad_or_truncate(X_train, expected_length)\n",
    "X_dev = pad_or_truncate(X_dev, expected_length)\n",
    "X_test = pad_or_truncate(X_test, expected_length)\n",
    "\n",
    "# Reshape data for CNN\n",
    "X_train = X_train.reshape(-1, timesteps, features_per_timestep, 1)\n",
    "X_dev = X_dev.reshape(-1, timesteps, features_per_timestep, 1)\n",
    "X_test = X_test.reshape(-1, timesteps, features_per_timestep, 1)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_dev_encoded = label_encoder.transform(y_dev)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(y_train_encoded)\n",
    "y_dev_categorical = to_categorical(y_dev_encoded)\n",
    "y_test_categorical = to_categorical(y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf92292-99a2-4703-b424-a5931b581ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(timesteps, features_per_timestep, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(y_train_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_categorical, validation_data=(X_dev, y_dev_categorical), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9235fa-cfa3-4324-8076-ce8170dd38e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.fit(X_train, y_train_categorical, validation_data=(X_dev, y_dev_categorical), epochs=100, batch_size=32, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988a977b-4a90-49a3-8181-9c8c4ee81f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint('best_weights.h5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30229d58-ee40-461d-a8f3-78664484c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# This callback will monitor the validation loss (val_loss) of your model.\n",
    "# If the validation loss doesn't improve for 5 (patience=5) consecutive epochs, it'll stop the training.\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# fitting the model, include the callback in the 'callbacks' parameter.\n",
    "# due to the early stopping callback, it may stop earlier if the validation loss doesn't improve for 5 consecutive epochs.\n",
    "model.fit(X_train, y_train_categorical, validation_data=(X_dev, y_dev_categorical), epochs=100, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "model.fit(X_train, y_train_categorical, validation_data=(X_dev, y_dev_categorical), epochs=100, batch_size=32, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3900b4-20ef-4c70-84e9-a48e9894332d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First Convolutional Layer\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))  # Add dropout of 25%\n",
    "\n",
    "# Second Convolutional Layer\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))  # Add dropout of 25%\n",
    "\n",
    "# Flatten and Fully Connected Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))  # L2 regularization\n",
    "model.add(Dropout(0.5))  # Add dropout of 50%\n",
    "model.add(Dense(y_train_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_categorical, validation_data=(X_dev, y_dev_categorical), epochs=100, batch_size=32, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db985f4d-07c3-4658-b276-70809175a4ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First Convolutional Layer\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second Convolutional Layer\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten and Fully Connected Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(y_train_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "# Use RMSprop optimizer as an alternative\n",
    "optimizer = RMSprop(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_categorical, validation_data=(X_dev, y_dev_categorical), epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec4b5ed-cf72-49c4-ab31-b44f4481c084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
